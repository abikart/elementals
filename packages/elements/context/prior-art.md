# Adaptive UI Prior Art

## Summary of tweets, Thread on twitter about adaptive UI: https://x.com/paultoo/status/1861891073775444446
* I spent 10 minutes googling for a market cap chart and couldn't find a decent one, so I made one with Replit Agent in two minutes. Still can't believe you can make software faster than you can google for it.
* The next generation of AI tools should have a completely adaptive UI, entirely generated by the AI itself. Any time I want a new feature or different interface, I just tell the AI and it makes the necessary changes. Zero static / hard-coded UI elements. Is anyone building this?
* We are doing this with infrastructure and networking: Meet Meter Command. A generative UI product for getting information, taking action, and building real-time software â€“ all in natural language. http://meter.com/command
    * Q: If they aren't static how will you recognize them on subsequent uses?. Ans: It starts with reasonable defaults and remembers everything you've ever told it. in addition to user memory we think it should also have company & domain memory/fine tuning.
* Yep: https://patinasystems.com/ (Patina is building "spontaneous, adaptive, malleable, ephemeral" software)
* I think we'll see both preset UIs and adaptive UIs coexist. Using an analogy of movies and video games: movies, the director curates a set story for you, video games you build the story yourself through your actions. There's a time and place for both, and don't replace each other.
    * Response: An adaptive UI with a good initial default seems strictly superior to a fixed/preset UI (one can always choose to leave it as-is)
    * Response: so your take is that the UI is "structured", but then the user can "edit" with AI? i think about it a little differently. i think we want developers/product teams to develop primitives and the LLM understand intent from 'context' and recombine & customize to solve the users needs better.
- 100% I think of this as task and user specific ephemeral/disposable UI. @mrmagan_  is building this at http://usehydra.ai. (AI-powered router surfaces the right features to users based on context)
* Yes try @ac1dotai . We do everything for you end-to-end. Including setting up databases, migrating data automatically when the data model changes, and taught the agent how to use SoTA LLMs. People have been building everything from static personal websites to deeply interactive SaaS. Lmk what you think!
* Yes. There seems to be a direct line between UI preferences (how it should be adapted) and the results of personality tests. Tried a few different tests, including brand archetypes, a Carl Yung-inspired framework, and the level of accuracy is crazy high especially when using few test results in parallel. This can improve UX a lot by getting the "right" UI right upfront. But taking a test is a friction (although if the number of Qs is low and framed interestingly, users don't seem to churn). Another observation is that there could be good use for fixed UI elements; jury is not out here but depending on the use case, it may be helpful for users to have a familiar starting point before the adaptive UI kicks in. In my use case (ai business partner for creatives to start and grow their agencies - we're taking a "compound startup" approach to automate all of their business processes) the way to think of the UI is neither fixed nor adaptive - but simply as a "frictionless" medium to convert highly abstract commands into the ideal outcomes (which may require multi-step actions, now done via human agents, who we are replacing with ai agents)
* I like to think about it as 'single use UI'. It worked for plastic, why not software? UI programming is the single most expensive part of software development. There's a range from generating UI from data schemas to fully custom. AI can help with both. Working on it
* How about the device monitoring your behavior and making UI changes to support that on its own. If I don't use Marketplace on FB then put that link way down.
* I still think you'd be better off pre-generating hundreds or even thousands of custom UI elements and setups for a variety of input files and work flow and intelligently selecting from them rather than generate everything from scratch on the spot. That way you can have better quality control and performance, and it would be easier to gain proficiency because the same workflows or very similar workflow with the same input/file would have a very similar and consistent UI.
* I envision personalized software experiences in every aspect. For instance, when I switch music tracks on my Apple Watch, the user experience should delay returning to the workout interface by half a second to accommodate my frequent track changes. Software defaults should function like algorithmic feeds, starting users in the same place but diverging significantly based on individual usage.
* This is dumb, AI should learn from its environment and makes changes at its own code real time. If you still need to tell it then it isn't good enough.
* This is the most believable vision I've heard of what a native ai app layer may look like. Needs an improvement in coding frameworks similar to how ajax unlocked gmail.
* Apps like this make sense, but if everything worked this way, it'd be like making a light switch probabilistic just because you can. Some things are better kept simple.
* I've been dreaming and been working on the theory about contextual for the last 17 years. Now it's on a level where it's possible to build UIs that are even more dynamic, the easy solution is too use well defined building blocks, the more advanced will be to let AI build itself
* Exactly what we built. AI decide what GUI to generate to interact with the user based on current context as well as the objective provided by the developer. AI knows the backend api spec so it can generate reasonable input and output UI.
* Hybrid is how I see it playing. Static UI + Adaptive UI. You have your main app value and a specific section that will be an adaptive UI.Data intensive applications (healthcare, finance, etc) will benefit a lot from this adaptive UI
* We're doing this for supply chain companies using ancient ERPs like SAP/Netsuite, where instead of modules the UI adapts to whatever the user is trying to achieve in that moment.
* Absolutely fkn not. Not only is that a BS pipe dream, it would break on every build. I don't know what llm PR line you're snorting, but you're about a million miles off the mark.
* I think issues with zero static are a) psychological benefits of a stable UI b) sensitivity to how requests are made c) cognitive effort to know what to ask for. A lot of use cases just don't need that. But I agree personalised UI is a winner. You could open source your UI by adding stable features created by users to solve their own issues with your site
* "Spontaneous, adaptive, malleable, ephemeral" (Patina)
* "Single use UI" (Plastic analogy)
* "Structured fluidity" (Hybrid approach)
* "Recombinant Interfaces" (from component architecture focus)
* "Ephemeral UI" (from Hydra's "single-use" concept)
* "Fluid UI Systems" (combines adaptation + generation)